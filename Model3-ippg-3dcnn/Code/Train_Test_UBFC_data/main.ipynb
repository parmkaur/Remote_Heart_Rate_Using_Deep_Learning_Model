{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y_zo1yUmdUm"
   },
   "source": [
    "# 3D convolutional neural networks for remote pulse rate measurement and mapping from facial video by Frédéric Bousefsaf \n",
    "\n",
    "\n",
    "### MIT License Copyright (c) 2019 Frédéric Bousefsaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "5-4iSwG2sHnd"
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import os\n",
    "import cv2\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.models import model_from_json\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.python.keras.layers import ZeroPadding3D, Dense, Activation,Conv3D,MaxPooling3D,AveragePooling3D,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "2N2UyBco2Tb7"
   },
   "outputs": [],
   "source": [
    "#folder where all the images within their specific heart rate label are stored\n",
    "Training_Dataset_Folder = \"/content/drive/MyDrive/Method1-3DCNN/Training_data/\"\n",
    "Testing_Dataset_Folder = \"/content/drive/MyDrive/Method1-3DCNN/Training_data/\"\n",
    "BATCH_SIZE = 60\n",
    "IMAGE_WIDTH = 25\n",
    "IMAGE_HEIGHT = 25\n",
    "IMAGE_CHANNELS = 1\n",
    "\n",
    "CONTINUE_TRAINING = True\n",
    "SAVE_ALL_MODELS = False\n",
    "\n",
    "training_loss = []\n",
    "training_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhpOMnp-u-Ui",
    "outputId": "d0ed490d-77a3-48c5-9b31-798795a4996d"
   },
   "outputs": [],
   "source": [
    "#Load the list of used heart rate labels for Training and Testing\n",
    "#total of 76 heart rate labels used for training and testing this model\n",
    "#heart rates for training and testing must be same\n",
    "\n",
    "hr_labels = pd.read_csv('/content/drive/MyDrive/Method1-3DCNN/hr_labels.csv', sep=',',header=None) #contains the list of heart rate labels\n",
    "hr_labels = pd.DataFrame(label).to_numpy()\n",
    "labels = np.zeros(len(labels))\n",
    "print(labels)\n",
    "#create list of heart rate labels\n",
    "for i in range(len(hr_labels)):\n",
    "    labels[i] = i\n",
    "\n",
    "#assigning category tag to heart rate labels\n",
    "labels_cat = np_utils.to_categorical(labels)\n",
    "\n",
    "#converting heart rates into numpy array\n",
    "hr_labels = np.reshape(hr_labels,[len(hr_labels)])\n",
    "print(hr_labels)\n",
    "\n",
    "NB_CLASSES = len(labels) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "X8yYFUzGuJiV"
   },
   "outputs": [],
   "source": [
    "#count the total number of images in all training heart rate labels folders\n",
    "training_images_counter=0\n",
    "testing_images_counter=0\n",
    "for images_labels in range(len(hr_labels)):\n",
    "    dir = Training_Dataset_Folder + str(hr_labels[images_labels])\n",
    "    list = os.listdir(dir)\n",
    "    images_count = len(list) #images_count contains images in every heart rate folder\n",
    "    for i in range(images_count):\n",
    "        training_images_counter+=1\n",
    "#count the total number of images in all testing heart rate labels folders\n",
    "for images_labels in range(len(hr_labels)):\n",
    "    dir = Testing_Dataset_Folder + str(hr_labels[images_labels])\n",
    "    list = os.listdir(dir)\n",
    "    images_count = len(list) #images_count contains images in every heart rate folder\n",
    "    for i in range(images_count):\n",
    "        testing_images_counter+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVtv_Twnw3bW",
    "outputId": "8ac6b8c3-732d-485c-91dd-abe32dcfd687"
   },
   "outputs": [],
   "source": [
    "training_images_counter=0\n",
    "testing_images_counter=0\n",
    "\n",
    "x_train = np.zeros([training_images_counter,BATCH_SIZE, IMAGE_HEIGHT,IMAGE_WIDTH])\n",
    "y_train =  np.zeros([training_images_counter,len(labels)])\n",
    "x_test = np.zeros([testing_images_counter,BATCH_SIZE, IMAGE_HEIGHT,IMAGE_WIDTH])\n",
    "y_test =  np.zeros([testing_images_counter,len(labels)])\n",
    "\n",
    "#Grab all the images from training dataset directory\n",
    "for images_labels in range(len(hr_labels)):\n",
    "    dir = Training_Dataset_Folder  + str(hr_labels[images_labels])\n",
    "    list=os.listdir(dir)\n",
    "    images_count = len(list) #images_count contains images in every heart rate folder\n",
    "    for i in range(images_count):\n",
    "            image = Training_Dataset_Folder + str(hr_labels[images_labels]) +'/'+ str(i+1) +'.jpg'\n",
    "            image = asarray(Image.open(image))\n",
    "            print(image.shape)\n",
    "            tiled_image = np.tile(image,[60,1,1])\n",
    "            x_train[training_images_counter,:,:,:] = tiled_image[:,:,:]\n",
    "            y_train[training_images_counter] = labels_cat[images_labels]\n",
    "            training_images_counter+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-joX14JuxNhF",
    "outputId": "9a82b85f-1456-4b5f-9541-11e59635429b"
   },
   "outputs": [],
   "source": [
    "#Grab all the images from testing dataset directory\n",
    "for images_labels in range(len(hr_labels)):\n",
    "    dir = Testing_Dataset_Folder  + str(hr_labels[images_labels])\n",
    "    list=os.listdir(dir)\n",
    "    images_count = len(list) #images_count contains images in every heart rate folder\n",
    "    for i in range(images_count):\n",
    "        image = Testing_Dataset_Folder + str(hr_labels[images_labels]) +'/'+ str(i+1) +'.jpg'\n",
    "        image = asarray(Image.open(image))\n",
    "        print(image.shape)\n",
    "        tiled_image = np.tile(image,[60,1,1])\n",
    "        x_test[testing_images_counter,:,:,:] = tiled_image[:,:,:]\n",
    "        y_test[testing_images_counter] = labels_cat[images_labels]\n",
    "        testing_images_counter+=1\n",
    "            \n",
    "x_train = np.reshape(x_train, [x_train.shape[0], BATCH_SIZE, IMAGE_HEIGHT,IMAGE_WIDTH,1])\n",
    "x_test = np.reshape(x_test, [x_test.shape[0], BATCH_SIZE, IMAGE_HEIGHT,IMAGE_WIDTH,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAxVCqFbPRP1",
    "outputId": "7e2ac043-aa46-49c9-9155-ab5f3c3e99e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 3, 6, 6, 32)       742432    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 1, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1, 3, 3, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 76)                38988     \n",
      "=================================================================\n",
      "Total params: 929,388\n",
      "Trainable params: 929,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Defining  Model for training\n",
    "\n",
    "if(CONTINUE_TRAINING==True):\n",
    "        init_batch_nb = 0\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(filters=32,kernel_size=(58,20,20),input_shape=(BATCH_SIZE,IMAGE_HEIGHT,IMAGE_WIDTH,IMAGE_CHANNELS)))\n",
    "        model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(NB_CLASSES+1, activation='softmax'))\n",
    "\n",
    "else:\n",
    "        #load model\n",
    "        model = model_from_json(open('/content/drive/My Drive/Model1-3dcnn/model/model_conv3D.json').read())\n",
    "        model.load_weights('/content/drive/My Drive/Model1-3dcnn/model/weights_conv3D_%04d.h5')\n",
    "\n",
    "        #load statistics\n",
    "        dummy = np.loadtxt('loss.txt')\n",
    "        init_batch_nb = dummy.shape[0]\n",
    "        train_loss = dummy[:,0].tolist()\n",
    "        train_acc = dummy[:,1].tolist()\n",
    "\n",
    "#Show Model summary and compile the model\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 930
    },
    "id": "F6EWSw7iQUX7",
    "outputId": "15ee82fc-7add-45a4-e579-2395ec38dd8d"
   },
   "outputs": [],
   "source": [
    "#Training the Model\n",
    "EPOCHS = 100\n",
    "print('Start Training ...................')\n",
    "for i in range(EPOCHS):\n",
    "  print(\"EPOCH:\" + str(i+1)) \n",
    "  for batch_nb in range(total_batch_num):\n",
    "      history = model.train_on_batch(x_train, y_train)\n",
    "      train_loss.append(history[0])\n",
    "      train_acc.append(history[1])  \n",
    "# A. Save the model only if the accuracy is greater than before\n",
    "      if (SAVE_ALL_MODELS==False):\n",
    "          if (batch_nb > 0):\n",
    "              f1 = open('/content/drive/My Drive/Model1-3dcnn/model/statistics_loss_acc.txt', 'a')\n",
    "              model.save_weights('/content/drive/My Drive/Model1-3dcnn/model/weights_conv3D_%04d.h5', overwrite=True)   # save (trained) weights\n",
    "              print('A new model has been saved!\\n')\n",
    "          else:\n",
    "              if not os.path.exists('/content/drive/My Drive/Model1-3dcnn/model'):\n",
    "                  os.makedirs('/content/drive/My Drive/Model1-3dcnn/model')\n",
    "              f1 = open('/content/drive/My Drive/Model1-3dcnn/model/statistics_loss_acc.txt', 'w')\n",
    "              model_json = model.to_json()\n",
    "              open('/content/drive/My Drive/Model1-3dcnn/model/model_conv3D.json', 'w').write(model_json)        # save model architecture\n",
    "\n",
    "      \n",
    "      # B. Save the model every iteration\n",
    "      else:\n",
    "          if (batch_nb > 0):\n",
    "              f1 = open('/content/drive/My Drive/Model1-3dcnn/model/statistics_loss_acc.txt', 'a')\n",
    "        \n",
    "          else:\n",
    "            if not os.path.exists('/content/drive/My Drive/Model1-3dcnn/model'):\n",
    "                os.makedirs('/content/drive/My Drive/Model1-3dcnn/model')\n",
    "\n",
    "            f1 = open('/content/drive/My Drive/Model1-3dcnn/model/statistics_loss_acc.txt', 'w')\n",
    "            model_json = model.to_json()\n",
    "            open('/content/drive/My Drive/Model1-3dcnn/model/model_conv3D.json', 'w').write(model_json)                       # save model architecture\n",
    "\n",
    "          model.save_weights('/content/drive/My Drive/Model1-3dcnn/model/weights_conv3D_%04d.h5' % batch_nb, overwrite=True)    # save (trained) weights\n",
    "\n",
    "      \n",
    "     \n",
    "      print('training: ' + str(batch_nb + 1) + '/' + str(total_batch_num) + ' done')\n",
    "      print('training: loss=' + str(train_loss[batch_nb]) + ' acc=' + str(train_acc[batch_nb]))\n",
    "      print(\"EPOCH:\" + str(i+1) + \"/\" + str(EPOCHS)) \n",
    "      \n",
    "\n",
    "      # save learning state informations\n",
    "      f1.write(str(train_loss[batch_nb]) + '\\t' + str(train_acc[batch_nb]) + '\\n')\n",
    "      f1.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "--mA7zZ5z4Yo",
    "outputId": "98dc10b2-f5c7-470c-8a90-b687458f4b04"
   },
   "outputs": [],
   "source": [
    "#Test the model\n",
    "history = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmfCyzQp0FA1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "working3dcnn_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
