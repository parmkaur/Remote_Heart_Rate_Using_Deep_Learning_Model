'''
Code of 'Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks' 
By Zitong Yu, 2019/05/05
If you use the code, please cite:
@inproceedings{yu2019remote,
    title={Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks},
    author={Yu, Zitong and Li, Xiaobai and Zhao, Guoying},
    booktitle= {British Machine Vision Conference (BMVC)},
    year = {2019}
}
Only for research purpose, and commercial use is not allowed.
MIT License
Copyright (c) 2019 
'''

import math
import torch.nn as nn
from torch.nn.modules.utils import _triple
import pdb
import torch


class SpatioTemporalConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):
        super(SpatioTemporalConv, self).__init__()

		
        # if ints are entered, convert them to iterables, 1 -> [1, 1, 1]
        kernel_size = _triple(kernel_size)
        stride = _triple(stride)
        padding = _triple(padding)

        # decomposing the parameters into spatial and temporal components by
        # masking out the values with the defaults on the axis that
        # won't be convolved over. This is necessary to avoid unintentional
        # behavior such as padding being added twice
        spatial_kernel_size =  [1, kernel_size[1], kernel_size[2]]
        spatial_stride =  [1, stride[1], stride[2]]
        spatial_padding =  [0, padding[1], padding[2]]

        temporal_kernel_size = [kernel_size[0], 1, 1]
        temporal_stride =  [stride[0], 1, 1]
        temporal_padding =  [padding[0], 0, 0]

        # compute the number of intermediary channels (M) using formula 
        # from the paper section 3.5
        intermed_channels = int(math.floor((kernel_size[0] * kernel_size[1] * kernel_size[2] * in_channels * out_channels)/(kernel_size[1]* kernel_size[2] * in_channels + kernel_size[0] * out_channels)))
        
        # self-definition
        #intermed_channels = int((in_channels+intermed_channels)/2)

        # the spatial conv is effectively a 2D conv due to the 
        # spatial_kernel_size, followed by batch_norm and ReLU
        self.spatial_conv = nn.Conv3d(in_channels, intermed_channels, spatial_kernel_size,
                                    stride=spatial_stride, padding=spatial_padding, bias=bias)
        self.bn = nn.BatchNorm3d(intermed_channels)
        self.relu = nn.ReLU()   ##   nn.Tanh()   or   nn.ReLU(inplace=True)


        # the temporal conv is effectively a 1D conv, but has batch norm 
        # and ReLU added inside the model constructor, not here. This is an 
        # intentional design choice, to allow this module to externally act 
        # identical to a standard Conv3D, so it can be reused easily in any 
        # other codebase
        self.temporal_conv = nn.Conv3d(intermed_channels, out_channels, temporal_kernel_size, 
                                    stride=temporal_stride, padding=temporal_padding, bias=bias)

    def forward(self, x):
        x = self.relu(self.bn(self.spatial_conv(x)))  
        x = self.temporal_conv(x)                      
        return x


class MixA_Module(nn.Module):
    """ Spatial-Skin attention module"""
    def __init__(self):
        super(MixA_Module,self).__init__()
        self.softmax  = nn.Softmax(dim=-1)
        self.AVGpool = nn.AdaptiveAvgPool1d(1)
        self.MAXpool = nn.AdaptiveMaxPool1d(1)
    def forward(self,x , skin):
        """
            inputs :
                x : input feature maps( B X C X T x W X H)
                skin : skin confidence maps( B X T x W X H)
            returns :
                out : attention value
                spatial attention: W x H
        """
        m_batchsize, C, T ,W, H = x.size()
        B_C_TWH = x.view(m_batchsize,C,-1)
        B_TWH_C = x.view(m_batchsize,C,-1).permute(0,2,1)
        B_TWH_C_AVG =  torch.sigmoid(self.AVGpool(B_TWH_C)).view(m_batchsize,T,W,H)
        B_TWH_C_MAX =  torch.sigmoid(self.MAXpool(B_TWH_C)).view(m_batchsize,T,W,H)
        B_TWH_C_Fusion = B_TWH_C_AVG + B_TWH_C_MAX + skin
        Attention_weight = self.softmax(B_TWH_C_Fusion.view(m_batchsize,T,-1))
        Attention_weight = Attention_weight.view(m_batchsize,T,W,H)
        # mask1 mul
        output = x.clone()
        for i in range(C):
            output[:,i,:,:,:] = output[:,i,:,:,:].clone()*Attention_weight
        
        return output, Attention_weight    


# for open-source
# skin segmentation + PhysNet + MixA3232 + MixA1616part4
class rPPGNet(nn.Module):
    def __init__(self, frames=64):  
        super(rPPGNet, self).__init__()
        
        self.ConvSpa1 = nn.Sequential(
            nn.Conv3d(3, 16, [1,5,5],stride=1, padding=[0,2,2]),
            nn.BatchNorm3d(16),
            nn.ReLU(inplace=True),
        )

        self.ConvSpa3 = nn.Sequential(
            SpatioTemporalConv(16, 32, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(inplace=True),
        )
        self.ConvSpa4 = nn.Sequential(
            SpatioTemporalConv(32, 32, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(32),
            nn.ReLU(inplace=True),
        )
        
        self.ConvSpa5 = nn.Sequential(
            SpatioTemporalConv(32, 64, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
        )
        self.ConvSpa6 = nn.Sequential(
            SpatioTemporalConv(64, 64, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
        )
        self.ConvSpa7 = nn.Sequential(
            SpatioTemporalConv(64, 64, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
        )
        self.ConvSpa8 = nn.Sequential(
            SpatioTemporalConv(64, 64, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
        )
        self.ConvSpa9 = nn.Sequential(
            SpatioTemporalConv(64, 64, [3, 3, 3], stride=1, padding=1),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
        )
 
        self.ConvSpa10 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
        self.ConvSpa11 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
        self.ConvPart1 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
        self.ConvPart2 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
        self.ConvPart3 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
        self.ConvPart4 = nn.Conv3d(64, 1, [1,1,1],stride=1, padding=0)
           
        
        self.AvgpoolSpa = nn.AvgPool3d((1, 2, 2), stride=(1, 2, 2))
        self.AvgpoolSkin_down = nn.AvgPool2d((2,2), stride=2)
        self.AvgpoolSpaTem = nn.AvgPool3d((2, 2, 2), stride=2)
        
        self.ConvSpa = nn.Conv3d(3, 16, [1,3,3],stride=1, padding=[0,1,1])
        
        
        # global average pooling of the output
        self.pool = nn.AdaptiveAvgPool3d(1)
        self.poolspa = nn.AdaptiveAvgPool3d((frames,1,1))    # attention to this value 
        

        # skin_branch
        self.skin_main = nn.Sequential(
            nn.Conv3d(32, 16, [1,3,3], stride=1, padding=[0,1,1]),
            nn.BatchNorm3d(16),
            nn.ReLU(inplace=True),
            nn.Conv3d(16, 8, [1,3,3], stride=1, padding=[0,1,1]),
            nn.BatchNorm3d(8),
            nn.ReLU(inplace=True),
        )
        
        self.skin_residual = nn.Sequential(
            nn.Conv3d(32, 8, [1,1,1], stride=1, padding=0),
            nn.BatchNorm3d(8),
            nn.ReLU(inplace=True),
        )
        
        self.skin_output = nn.Sequential(
            nn.Conv3d(8, 1, [1,3,3], stride=1, padding=[0,1,1]),
            nn.Sigmoid(),   ## binary 
        )
        
        self.MixA_Module = MixA_Module()
        
    def forward(self, x):	    	# x [3, 64, 128,128]
        x_visual = x
          
        x = self.ConvSpa1(x)		     # x [3, 64, 128,128]
        x = self.AvgpoolSpa(x)       # x [16, 64, 64,64]
        
        x = self.ConvSpa3(x)		    # x [32, 64, 64,64]
        x_visual6464 = self.ConvSpa4(x)	    	# x [32, 64, 64,64]
        x = self.AvgpoolSpa(x_visual6464)      # x [32, 64, 32,32]
        
        
        ## branch 1: skin segmentation
        x_skin_main = self.skin_main(x_visual6464)    # x [8, 64, 64,64]
        x_skin_residual = self.skin_residual(x_visual6464)   # x [8, 64, 64,64]
        x_skin = self.skin_output(x_skin_main+x_skin_residual)    # x [1, 64, 64,64]
        x_skin = x_skin[:,0,:,:,:]    # x [74, 64,64]
        
        
        ## branch 2: rPPG
        x = self.ConvSpa5(x)		    # x [64, 64, 32,32]
        x_visual3232 = self.ConvSpa6(x)	    	# x [64, 64, 32,32]
        x = self.AvgpoolSpa(x_visual3232)      # x [64, 64, 16,16]
        
        x = self.ConvSpa7(x)		    # x [64, 64, 16,16]
        x = self.ConvSpa8(x)	    	# x [64, 64, 16,16]
        x_visual1616 = self.ConvSpa9(x)	    	# x [64, 64, 16,16]
        
        
        ## SkinA1_loss
        x_skin3232 = self.AvgpoolSkin_down(x_skin)          # x [64, 32,32]
        x_visual3232_SA1, Attention3232 = self.MixA_Module(x_visual3232, x_skin3232)
        x_visual3232_SA1 = self.poolspa(x_visual3232_SA1)     # x [64, 64, 1,1]    
        ecg_SA1  = self.ConvSpa10(x_visual3232_SA1).squeeze(1).squeeze(-1).squeeze(-1)
        
        
        ## SkinA2_loss
        x_skin1616 = self.AvgpoolSkin_down(x_skin3232)       # x [64, 16,16]
        x_visual1616_SA2, Attention1616 = self.MixA_Module(x_visual1616, x_skin1616)
        ## Global
        global_F = self.poolspa(x_visual1616_SA2)     # x [64, 64, 1,1]    
        ecg_global = self.ConvSpa11(global_F).squeeze(1).squeeze(-1).squeeze(-1)
        
        ## Local
        Part1 = x_visual1616_SA2[:,:,:,:8,:8]
        Part1 = self.poolspa(Part1)     # x [64, 64, 1,1]    
        ecg_part1 = self.ConvSpa11(Part1).squeeze(1).squeeze(-1).squeeze(-1)
        
        Part2 = x_visual1616_SA2[:,:,:,8:16,:8]
        Part2 = self.poolspa(Part2)     # x [64, 64, 1,1]    
        ecg_part2 = self.ConvPart2(Part2).squeeze(1).squeeze(-1).squeeze(-1)
        
        Part3 = x_visual1616_SA2[:,:,:,:8,8:16]
        Part3 = self.poolspa(Part3)     # x [64, 64, 1,1]    
        ecg_part3 = self.ConvPart3(Part3).squeeze(1).squeeze(-1).squeeze(-1)
        
        Part4 = x_visual1616_SA2[:,:,:,8:16,8:16]
        Part4 = self.poolspa(Part4)     # x [64, 64, 1,1]    
        ecg_part4 = self.ConvPart4(Part4).squeeze(1).squeeze(-1).squeeze(-1)
        
        

        return x_skin, ecg_SA1, ecg_global, ecg_part1, ecg_part2, ecg_part3, ecg_part4, x_visual6464, x_visual3232
